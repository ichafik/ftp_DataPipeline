{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python\n",
    "# -*- coding: utf-8 -*- \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LES IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Init part\n",
    "\n",
    "APPLICATION_NAME = \"FTP_PIPELINE\"\n",
    "import ftplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init (Don't modify this code, it is mandatory for both Development and Production modes)\n",
    "import os, sys\n",
    "def delPyc(pycFile):\n",
    "    os.remove(pycFile + \".pyc\") if os.path.exists(pycFile + \".pyc\") else None\n",
    "try: APPLICATION_HOME = os.environ[\"APPLICATION_HOME\"]\n",
    "except: APPLICATION_HOME = \"..\"\n",
    "delPyc(APPLICATION_HOME + \"/lib/SparkInit\")\n",
    "sys.path.append(os.path.abspath(APPLICATION_HOME + \"/lib\"))\n",
    "sys.path.append(os.path.abspath(APPLICATION_HOME + \"/src\"))\n",
    "from SparkInit import *\n",
    "from SparkFTP import * \n",
    "try: spark\n",
    "except: spark = None\n",
    "try: sc\n",
    "except: sc = None\n",
    "sparkInit = SparkInit(spark, sc, APPLICATION_HOME, DEFAULT_APPLICATION_NAME=APPLICATION_NAME)\n",
    "spark = sparkInit.spark\n",
    "sc = sparkInit.sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from IPython.display import display\n",
    "\n",
    "pandas.set_option('display.max_columns', 999)\n",
    "def showDataFrame(df, percent):\n",
    "    pandasDf = None\n",
    "    if (df != None):\n",
    "        sparkSampleDf = df.sample(False, percent, 43)\n",
    "        pandasDf = sparkSampleDf.toPandas()\n",
    "        display(pandasDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sparkInit.DEV_MODE :\n",
    "    print \"\"\n",
    "    print \"############################################################\"\n",
    "    print \"#                   FTP Data Load Pipeline                 #\"\n",
    "    print \"############################################################\"\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before starting with that lets create a csv on the ftp server\n",
    "# in this tutoriel the ftp server is nothing but the localhost 127.0.0.1\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération fichier df_calendaires_France à partir du FTP Datalab (df_ftp_calendaire)\n",
    "# Open connection to the FTP server snix0455 (Local_FTP)\n",
    "sparkFtp = SparkFTP(sc)\n",
    "sparkFtp.openFtpConnection(\"127.0.0.1\", 21, \"Tester_FTP\", \"testerftp\")\n",
    "ftpfiles =  sparkFtp.scanFtpFiles(\"/download/kaggle_dataset/\", recursive=False, startsWith=None, contains=None, endsWith=\".csv\") \n",
    "for i in ftpfiles:\n",
    "    if (i == '/download/kaggle_dataset/titanic.csv'):\n",
    "        df = sparkFtp.ftpCsvFileToSparkDf(i, isHeader=True, columns=None, columnDelimiter=';', lineDelimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDataFrame(df,1.0)\n",
    "#print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## write your df to the ftp server\n",
    "#Open connection to the FTP server snix0455 (Local_FTP)\n",
    "# sparkFtp.closeFtpConnection()\n",
    "sparkFtp = SparkFTP(sc)\n",
    "sparkFtp.openFtpConnection(\"127.0.0.1\", 21, \"Tester_FTP\", \"testerftp\")\n",
    "\n",
    "sparkFtp.sparkDfToFtpCsvFile(df, \"/user/data/write/kaggle_ftp.csv\", isHeader=True, columnDelimiter=';',lineDelimiter='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3 Spark-2.4.6 Local(All cores)",
   "language": "python",
   "name": "spark-2.4.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
